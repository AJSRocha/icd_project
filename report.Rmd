---
date: "`r Sys.Date()`"
author: "Miguel Tavares, Hélder Vieira, Alberto Rocha"
title: "Relatório sobre o Projecto de Introdução a Ciência de Dados 2020/2021"
output: 
  officedown::rdocx_document:
    reference_docx: C://officedown.docx
    mapstyles:
      Normal: ['First Paragraph']
---

```{r setup, include=FALSE, echo = F}
knitr::opts_chunk$set(echo = TRUE, fig.cap = TRUE)
library(officedown)
library(officer)

fp <- fp_par(
  text.align = "center", 
  padding.bottom = 20, padding.top = 120, 
  border.bottom = fp_border())

ft <- fp_text(shading.color='#EFEFEF', bold = TRUE)
```

```{r, echo = F, include = F}

Sys.setenv(CUDA_VISIBLE_DEVICES = "-1")
    disabled <- c("disabled", "GPU")
library(ggplot2)
library(dplyr)
library(tidyverse)
library(caret)
library(kernlab)
library(pROC)
library(tensorflow)
library(keras)
set.seed(69)  
```

```{r data_input, echo = F, include = F}
df_temp <- read.csv("df_final.csv", dec = ".")

names(df_temp) <- c("ID","Peso","Altura",
                    "IMC","IDADE",
                    "PA_SISTOLICA","PA_DIASTOLICA",
                    "PATOLOGIA","B2","SOPRO",
                    "FC","HDA1","HDA2",
                    "SEXO","MOTIVO")
df_temp <-
df_temp  %>%  select(PATOLOGIA,Peso,Altura,IMC,IDADE,
                       PA_SISTOLICA,PA_DIASTOLICA,
                       FC, HDA1, HDA2, B2, SOPRO,
                       MOTIVO, SEXO) %>% drop_na %>%
  mutate(PATOLOGIA = relevel(factor(PATOLOGIA),ref = "Normal"),
         HDA1 = factor(HDA1),
         HDA2 = factor(HDA2),
         B2 = factor(B2),
         SOPRO = factor(SOPRO),
         MOTIVO = factor(MOTIVO),
         SEXO = factor(SEXO)) 

# SOPRO
df_num <- df_temp %>% select(PATOLOGIA, Peso, Altura, IDADE, PA_SISTOLICA, PA_DIASTOLICA, FC)
# B2
```

```{r frame, echo = F, include = F}
index <- caret::createDataPartition(paste(df_temp$PATOLOGIA,
                                          df_temp$B2,
                                          df_temp$HDA1,
                                          df_temp$HDA2,
                                          df_temp$SOPRO,
                                          df_temp$MOTIVO,
                                          df_temp$SEXO),
                                          p = 0.8, list = F)

control <- caret::trainControl(method = "cv", number = 10)
```

```{r, echo = F}
modelo <- as.formula(
          PATOLOGIA ~ Peso + Altura + IDADE +
          PA_SISTOLICA + PA_DIASTOLICA +
          SOPRO + FC + HDA1 + HDA2 + B2 +
          MOTIVO + SEXO)

modelo_num <- as.formula(PATOLOGIA ~ Peso + Altura + 
                           IDADE + PA_SISTOLICA + PA_DIASTOLICA + FC)
```

# Introduction

Our goal with this work is to assess the performance of several different machine learning techniques in predicting the occurrence of cardiac pathology in pacients, given the predictors available in the 'UCMF' dataset that was provided. This dataset consists of clinical records of children between 0 and 19, collected in the Real Hospital Português, in Brazil.

# Available data

Below follows a description of the variables provided in the dataset as well as the processing that was performed on them. It should be noted that they are presented sequentially in the order which they were treated, so stats such as the ammount of missing values in a given variable already take into account previously excluded observations that would otherwise inflate that number.

## **PATOLOGIA**

This is our target variable whose occurrence we intend to model. It has two levels: 'Normal' and 'Anormal' (abnormal), although they are presented with different spellings. Spelling variations were aggregated into the 2 fundamental levels. We rejected observations with missing values on this variable, accounting for 1168 observations.

```{r, echo = F, include = T, tab.id = "tabv1", tab.cap = "Distribution of the observations on the 'PATOLOGIA' variable in the processed dataset"}

table(df_temp$PATOLOGIA,dnn = "levels") %>% data.frame 
```

## **IDADE**

This variable represents age of the subjects. Observations outside of the ]0,20] range were rejected as they were either obvious input mistakes, such as negative ages, or ages outside of the intended range of this study (children and teenagers).

```{r, echo = F, fig.id = "edaidade", fig.cap= "Response of the variable 'PATOLOGIA' according to 'IDADE', grouped by age cohorts", fig.height = 6 }

gridExtra::grid.arrange(

df_temp %>% 
  ggplot +
  geom_histogram(aes(x = IDADE), binwidth = 1,fill = 'white', col = 'black') + 
  theme_light()
,
df_temp %>%
  mutate(IDADE = factor(trunc(IDADE))) %>%
  select(IDADE,PATOLOGIA) %>%
  table() %>%
  data.frame() %>%
  ggplot +
  geom_tile(aes(x = IDADE, y = PATOLOGIA, fill = Freq)) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = 'bottom'),
nrow=2)
```

## **SEXO**

This variable encodes the gender of the patient. After uniformization of the levels, we have considered 3 levels: Male, Female and Indetermined. Indetermined cases were a minority (398) so those observations were excluded.

```{r, echo = F, fig.id = "edasexo", fig.cap= "Response of the variable 'PATOLOGIA' according to 'SEXO", warning = F, message = F}

gridExtra::grid.arrange(

df_temp %>% 
  ggplot +
  geom_histogram(aes(x = SEXO), binwidth = 1,fill = 'white', col = 'black', stat = 'count') + 
  theme_light()
,
df_temp %>%
  mutate(IDADE = factor(trunc(IDADE))) %>%
  select(IDADE,PATOLOGIA) %>%
  table() %>%
  data.frame() %>%
  ggplot +
  geom_tile(aes(x = IDADE, y = PATOLOGIA, fill = Freq)) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = 'bottom'),
nrow=2)
```

## **Peso**, **Altura** and **IMC**

These variables correspond to weight, height and body-mass index. These variables are expected to be important in assessing the likelihood of pathology occurrence, since they are directly linked to physical constitution. Missing values were inputated by performing polynomial regression on existing data. **IMC** for the inputated observations were calculated. A table \@ref from the World Health Organization (WHO) was then used as a reference for BMI distributions per age. Observations with a BMI below 0.8 * [3 *percentile*] or above 1.2 * [97 *percentile*] on their age class were excluded as outliers. 648 observations were thus excluded.

## **SOPRO**

This variable refers to the existence and type of heart murmur. For the purposes of this work, it was encoded to a binary factor corresponding to presence or absence of a murmur on the patient.

## **B2**


## Rejected variables

The variables **ID**, **Convenio**, **Atendimento** and **DN** were not considered to be useful as reasonable preditors for cardiac pathology in the scope of this work and therefore will not be analized here. **PPA** consists on a classification of severity of hypertension, attributed according to the rank of the individual in the percentiles of expected distributions for BMI, age, gender, sistolic and diastolic pulse levels. Since we are using these variables in our models, such classification would be highly correlated with those variables. We have chosen to exclude **PPA** from our analysis. **PULSOS** (pulse) had 99.3% observations recorded as 'Normal'. Therefore we do not expect it to carry any significative correlation with our target variable or predictive power in the models we will be exploring. 

```{r, echo = F, include = F}
# df_core <- readxl::read_xls("UCMF.xls")
# 
# # corrigimos nome das variaveis
# names(df_core) <- c("ID","Peso","Altura",
#                     "IMC","Atendimento","DN",
#                     "IDADE","Convenio","PULSOS",
#                     "PA_SISTOLICA","PA_DIASTOLICA","PPA",
#                     "PATOLOGIA","B2","SOPRO",
#                     "FC","HDA1","HDA2",
#                     "SEXO","MOTIVO1","MOTIVO2")
# 
# # rejeitamos observaçoes sem variavel resposta
# df <- df_core %>% filter(!is.na(PATOLOGIA))
# 
# ## corrigimos os niveis da variavel
# df$PATOLOGIA <- factor(df$PATOLOGIA)
# levels(df$PATOLOGIA) <- c("Anormal","Anormal","Normal","Normal")
# 
# # IDADES
# df <- df[df$IDADE > 0 & df$IDADE <= 20 & !is.na(df$IDADE),]
# df$IDADE_class <- trunc(df$IDADE)
# 
# # SEXO
# df$SEXO <- factor(df$SEXO)
# levels(df$SEXO) <- c("F","F","I","M","M","M")
# 
# # Decisão: rejeitar sexo I
# df <- df[df$SEXO != "I",]
# 
# 
# 
# df$HDA1[is.na(df$HDA1)] <- "Sem Historico"
# df$HDA1 <- factor(df$HDA1) 
# levels(df$HDA1)
# 
# df$HDA2[is.na(df$HDA2)] <- "Sem Historico"
# df$HDA2 <- factor(df$HDA2)
# levels(df$HDA2)
# 
# df$SOPRO <- factor(df$SOPRO)
# levels(df$SOPRO) <- c("ausente", "presente", "presente",
#                       "presente","presente","presente",
#                       "presente")
# 
# df_temp <- df %>% drop_na %>%
#   filter(PA_SISTOLICA<500) %>%
#   select(PATOLOGIA,Peso,Altura,IMC,IDADE,
#          PULSOS,PA_SISTOLICA,PA_DIASTOLICA,
#          PPA,SOPRO,FC,
#          HDA1,HDA2, B2,
#          MOTIVO1,MOTIVO2)
# 
# df_num <- df_temp %>% select(PATOLOGIA, Peso, Altura, IDADE, PA_SISTOLICA, PA_DIASTOLICA, FC)
```

# Tested Models

The model that has been tested in this work is thus:

$$
PATOLOGIA \sim Peso + Altura + Idade + PA\_SISTOLICA + PA\_DIASTOLICA + SOPRO + FC + HDA1 + HDA2 + MOTIVO 
$$



## Logistic Regression

```{r}
# source("R_0040_logistic_regression.R")
```

## Support Vector Machines - Linear kernel

várias opções: 'svmLinear', 'svmLinear2', 'svmLinear3'

```{r}
# source("R_0050_SVM.R")
```


## Linear Discriminant Analysis

Elevada colinearidade das variaveis categoricas?

```{r}
# source("R_0060_LDA.R")
```

## Naive Bayes

```{r}
# source("R_0070_NBayes.R")
```


## Random Forest

Testar tambem com preditores categoricos

```{r}
# source("R_0080_RF.R")
```


## Recurring Neural Network


```{r}
# source("R_000_RNN.R")
```

## ROC plots

```{r ROC, eval = F, echo = F, include = F}

# roc.glm<-roc(train$HOF,predict(train.log),plot=T,legacy.axes=T,print.auc=T)
# data.frame(tpp=roc.glm$sensitivities*100.,
#            fpp=(1-roc.glm$specificities)*100,
#            thresholds=roc.glm$thresholds) %>% head
par(pty="s")

#logistic regression
plot.roc(df_temp$PATOLOGIA,predict(train.log,type="response"),
         legacy.axes=T,
         print.auc=T,
         percent=T,
         col="#4daf4a",
         print.auc.y=60)
#logistic regression with undersampling
plot.roc(train.us$HOF,predict(train.us.log,type="response"),
         legacy.axes=T,
         print.auc=T,
         percent=T,
         col="lightblue",
         print.auc.y=50,
         add=T)
#random forests
plot.roc(train$HOF,train.rf$votes[,1],
         legacy.axes=T,
         print.auc=T,
         percent=T,
         col="red",
         print.auc.y=40,
         add=T)
#random forests
plot.roc(train.us$HOF,train.us.rf$votes[,1],
         legacy.axes=T,
         print.auc=T,
         percent=T,
         col="orange",
         print.auc.y=30,
         add=T)
#lda
# plot.roc(train$HOF,predict(train.lda)$x[,1],
#          legacy.axes=T,
#          print.auc=T,
#          percent=T,
#          col="purple",
#          print.auc.y=20,
#          add=T)

legend("bottomright",legend=c("logistic regression","log. unders.","random forests","rad.for under"),
       col=c("#4daf4a","lightblue","red","orange"),lwd=4,cex=0.6)

```
